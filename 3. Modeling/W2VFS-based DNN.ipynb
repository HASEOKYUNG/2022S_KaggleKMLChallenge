{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for load data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (os.path.abspath(\"./input\"))\n",
    "\n",
    "# 비정형 데이터인 text를 Word2Vec한 Feature만을 사용한다.\n",
    "X_train = pd.read_csv(path +'/feature_train_W2V.csv', encoding='cp949')\n",
    "X_test = pd.read_csv(path +'/feature_test_W2V.csv', encoding='cp949')\n",
    "y_train = pd.read_csv(path +'/y_train.csv', encoding='cp949').group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ID, test_ID = X_train.custid, X_test.custid\n",
    "del X_train['custid'], X_test['custid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 한 개의 회차 데이터만을 사용한다.\n",
    "SKF = list(StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0).split(X_train, y_train))[3]\n",
    "\n",
    "tr_X, val_X = X_train.iloc[SKF[0]], X_train.iloc[SKF[1]]\n",
    "tr_y, val_y = y_train.iloc[SKF[0]], y_train.iloc[SKF[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y = keras.utils.to_categorical(tr_y.astype('category').cat.codes)\n",
    "val_y = keras.utils.to_categorical(val_y.astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17270, 1530), (17270, 8), (4317, 1530), (4317, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_X.shape, tr_y.shape, val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scailing\n",
    "scaler = StandardScaler()\n",
    "tr_X = scaler.fit_transform(tr_X)\n",
    "val_X = scaler.transform(val_X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds(s1,s2,s3, reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  # optional\n",
    "\n",
    "    np.random.seed(s1)\n",
    "    random.seed(s2)\n",
    "    tf.compat.v1.set_random_seed(s3)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # for GPU\n",
    "#    print(\"RANDOM SEEDS RESET\")  # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seeds(7,77,777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(hp):\n",
    "    inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "    x = inputs\n",
    "    for i in range(hp.Int('num_layers', 2, 3)):\n",
    "        x = keras.layers.Dense(hp.Int('unit_'+str(i), 20, 61, step=10), hp.Choice('activation', ['relu', 'elu']))(x)\n",
    "        x = keras.layers.Dropout(hp.Float('dropout_'+str(i), 0, 0.5, step=0.1, default=0.5))(x) \n",
    "    outputs = keras.layers.Dense(8, activation='softmax')(x) # 예측값이 8종류이므로 8개 출력 뉴런 필요\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss='categorical_crossentropy', # Multiclass Classification에서 사용하는 loss function\n",
    "                  optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [0.01, 0.03])), \n",
    "                  metrics=[keras.metrics.CategoricalCrossentropy()]) # Multiclass Classification에서 사용하는 평가지표\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fn(hp):\n",
    "#     inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "#     x = inputs\n",
    "#     for i in range(hp.Int('num_layers', 2, 3)):\n",
    "#         x = keras.layers.Dense(hp.Int('unit_'+str(i), 16, 64, step=16), activation='relu')(x)\n",
    "#         x = keras.layers.Dropout(hp.Float('dropout_'+str(i), 0, 0.5, step=0.25, default=0.5))(x)\n",
    "#     outputs = keras.layers.Dense(8, activation='softmax')(x) # 예측값이 8종류이므로 8개 출력 뉴런 필요\n",
    "#     model = keras.Model(inputs, outputs)\n",
    "#     model.compile(loss='categorical_crossentropy', # Multiclass Classification에서 사용하는 loss function\n",
    "#                   optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
    "#                   metrics=[keras.metrics.CategoricalCrossentropy()]) # Multiclass Classification에서 사용하는 평가지표\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 Complete [00h 00m 24s]\n",
      "val_categorical_crossentropy: 2.0298824310302734\n",
      "\n",
      "Best val_categorical_crossentropy So Far: 1.6029775142669678\n",
      "Total elapsed time: 00h 33m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_fn,\n",
    "                     objective=kt.Objective('val_categorical_crossentropy', direction=\"min\"), \n",
    "                     max_epochs=30,\n",
    "                     hyperband_iterations=2,\n",
    "                     overwrite=True,\n",
    "                     directory=(os.path.abspath(\"./src\"))+'/dnn_tuning_3')\n",
    "tuner.search(tr_X, tr_y, validation_data=(val_X, val_y), \n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:\\Users\\ha\\+Competition\\src/dnn_tuning_3\\untitled_project\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002356E41E3D0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "unit_0: 20\n",
      "activation: relu\n",
      "dropout_0: 0.1\n",
      "unit_1: 60\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.01\n",
      "unit_2: 40\n",
      "dropout_2: 0.1\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0136\n",
      "Score: 1.6029775142669678\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(1)[0]  \n",
    "tuner.results_summary(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model & Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(model.predict(X_test))\n",
    "submissions = pd.concat([test_ID, pred] ,axis=1)\n",
    "submissions.columns = ['ID','F20','F30','F40','F50','M20','M30','M40','M50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = (os.path.abspath(\"./submission\"))\n",
    "\n",
    "fname = f'/MDNN_FW2V.csv'\n",
    "submissions.to_csv(sub_path+fname, index=False)\n",
    "print(\"'{}' is ready to submit.\" .format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
