{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14de03ca",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bbab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for read data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# for feature transform\n",
    "# Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, Normalizer, StandardScaler, MaxAbsScaler\n",
    "# Transformer\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer, FunctionTransformer\n",
    "# Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Evaluate Transformation\n",
    "from lightgbm import LGBMClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e52ad",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4185d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (os.path.abspath(\"./input\"))\n",
    "\n",
    "# Word2Vec, BOW는 Transfomation하지 않아 1-1에서 만든 Feature만을 Transformation한다.\n",
    "feature_train = pd.read_csv(path +'/feature_train.csv', encoding='cp949')\n",
    "feature_test = pd.read_csv(path +'/feature_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv(path +'/y_train.csv', encoding='cp949').group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139fba04",
   "metadata": {},
   "source": [
    "## Classify Features\n",
    "feature 데이터가 Tail data로 Boosting모델을 사용할 것이다. Boosting모델 중 속도가 빠른 `LGBM`을 기준모델로 하여 <br>\n",
    "여러 조합의 Feature Transformation의 Log Loss값을 보고 최적의 Transformation 조합을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f09ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_list = feature_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d1b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custid 제외\n",
    "classify_list.remove('custid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382686b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding 이전의 Category Feature\n",
    "cat_uncode = feature_train.select_dtypes(include='O').columns.tolist()\n",
    "cat_store = [i for i in cat_uncode if ('매장' in i) or ('지점' in i)]\n",
    "cat_brd = [i for i in cat_uncode if '브랜드' in i]\n",
    "cat_corner = [i for i in cat_uncode if '코너' in i]\n",
    "cat_pc = [i for i in cat_uncode if '상품군' in i]\n",
    "cat_part = [i for i in cat_uncode if '파트' in i]\n",
    "cat_team = [i for i in cat_uncode if '팀' in i]\n",
    "cat_buyer = [i for i in cat_uncode if '바이어' in i]\n",
    "classify_list = [i for i in classify_list if i not in cat_uncode]\n",
    "\n",
    "# goodcd가 numeric으로 작성되어 자동으로 Encoding된 Category Feature와 여부를 0/1로 나타낸 Category Feature\n",
    "cat_encode = [i for i in classify_list if '주상품' in i] + ['1일1개']\n",
    "classify_list = [i for i in classify_list if i not in cat_encode]\n",
    "\n",
    "cat = cat_uncode + cat_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80545bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금액 Feature\n",
    "num_amount = [i for i in classify_list if (i[-1]==\"액\") or (i[-3]==\"액\")]\n",
    "classify_list = [i for i in classify_list if i not in num_amount]\n",
    "\n",
    "# 비율 Feature\n",
    "num_percent = [i for i in classify_list if (i[-1]==\"율\") or (i[-3]==\"율\") or (i[-1]==\"률\") or (i[-3]==\"률\")]\n",
    "classify_list = [i for i in classify_list if i not in num_percent]\n",
    "\n",
    "# 개수/건수 Feature\n",
    "num_count = [i for i in classify_list if (i[-1]==\"수\") or (i[-3]==\"수\")]\n",
    "classify_list = [i for i in classify_list if i not in num_count]\n",
    "\n",
    "# 평균개월 등의 산출 Feature\n",
    "num_calculate = classify_list\n",
    "\n",
    "num = num_amount+num_percent+num_count+num_calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0fcced",
   "metadata": {},
   "source": [
    "- **[Imputation]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3982ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train NAN: 0 , test NAN: 0\n"
     ]
    }
   ],
   "source": [
    "print('train NAN:', feature_train.isna().sum().sum(), ',', 'test NAN:',feature_test.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c85137",
   "metadata": {},
   "source": [
    "- **[Outlier]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e05a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train[num] = feature_train[num].apply(lambda x: x.clip(x.quantile(.1), x.quantile(.1)), axis=0)\n",
    "feature_test[num] = feature_test[num].apply(lambda x: x.clip(x.quantile(.1), x.quantile(.1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1708f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler와 transformer는 LGBM을 이용해 최적의 조합을 찾는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d3d27",
   "metadata": {},
   "source": [
    "- **[Categorical Feature Encoding]**<br>\n",
    "  LGBM과 DNN에는 Encoding된 Feature를, Catboost에는 Unencoding된 Feature를 넣을 것이다. 분리해서 저장해야 한다.<br>\n",
    "  EDA에서 저장한 Frequency Encoding을 진행해보았으나 Label Encoding이 더 성능이 좋았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253df05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature train과 feature test를 합쳐서 Encoding 후 custid를 기준으로 분리한다.\n",
    "train_ID, test_ID = feature_train.custid, feature_test.custid\n",
    "feature = pd.concat([feature_train, feature_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16dd2aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for i in cat_uncode:\n",
    "    label = LabelEncoder()\n",
    "    feature[i] = label.fit_transform(feature[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3860deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = feature.query('custid in @train_ID').reset_index(drop=True)\n",
    "feature_test = feature.query('custid in @test_ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf2597",
   "metadata": {},
   "source": [
    "- **[Choose Best Feature Transformation Set for LGBM]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742807e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 사용을 위해 custid 제거 후 추후 concat한다.\n",
    "del feature_train['custid'], feature_test['custid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fafd241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y__train, y_dev = train_test_split(feature_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58582c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler만 사용할 때\n",
    "set_score = dict()\n",
    "\n",
    "def choose_best(scaler):\n",
    "    train_x, dev_x, train_y, dev_y = X_train.copy(), X_dev.copy(), y__train.copy(), y_dev.copy()\n",
    "    train_x[num] = scaler.fit_transform(train_x[num])\n",
    "    dev_x[num] = scaler.transform(dev_x[num])\n",
    "    \n",
    "    model = LGBMClassifier(objective='multiclass', metrics='multi_logloss', num_gpu=1, random_state=0)\n",
    "    model.fit(train_x, train_y)\n",
    "    set_score[f'{scaler}'] = log_loss(dev_y, model.predict_proba(dev_x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa8ce1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6479987931433973, 'MaxAbsScaler()')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in [MinMaxScaler(), RobustScaler(), Normalizer(), StandardScaler(), MaxAbsScaler()]:\n",
    "    choose_best(s)\n",
    "    \n",
    "sorted([(logloss, sets) for sets, logloss in set_score.items()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d57d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer만 사용할 때\n",
    "set_score = dict()\n",
    "\n",
    "def choose_best(transformer):\n",
    "    train_x, dev_x, train_y, dev_y = X_train.copy(), X_dev.copy(), y__train.copy(), y_dev.copy()\n",
    "    train_x[num] = transformer.fit_transform(train_x[num])\n",
    "    dev_x[num] = transformer.transform(dev_x[num])\n",
    "    \n",
    "    model = LGBMClassifier(objective='multiclass', metrics='multi_logloss', num_gpu=1, random_state=0)\n",
    "    model.fit(train_x, train_y)\n",
    "    set_score[f'{transformer}'] = log_loss(dev_y, model.predict_proba(dev_x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8496d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6479987931433973, \"FunctionTransformer(func=<ufunc 'log1p'>)\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in [FunctionTransformer(np.log1p), PowerTransformer(), QuantileTransformer(output_distribution='normal')]:\n",
    "    choose_best(t)\n",
    "    \n",
    "sorted([(logloss, sets) for sets, logloss in set_score.items()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71355fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler와 Transformer 모두 사용할 때\n",
    "set_score = dict()\n",
    "\n",
    "def choose_best(scaler, transformer):\n",
    "    train_x, dev_x, train_y, dev_y = X_train.copy(), X_dev.copy(), y__train.copy(), y_dev.copy()\n",
    "    train_x[num] = scaler.fit_transform(train_x[num])\n",
    "    dev_x[num] = scaler.transform(dev_x[num])\n",
    "    \n",
    "    train_x[num] = transformer.fit_transform(train_x[num])\n",
    "    dev_x[num] = transformer.transform(dev_x[num])\n",
    "    \n",
    "    model = LGBMClassifier(objective='multiclass', metrics='multi_logloss', num_gpu=1, random_state=0)\n",
    "    model.fit(train_x, train_y)\n",
    "    set_score[f'({scaler}, {transformer})'] = log_loss(dev_y, model.predict_proba(dev_x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50633dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in [MinMaxScaler(), RobustScaler(), Normalizer(), StandardScaler(), MaxAbsScaler()]:\n",
    "    for t in [FunctionTransformer(np.log1p), PowerTransformer(), QuantileTransformer(output_distribution='normal')]:\n",
    "        choose_best(s, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8385cf40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6479987931433973,\n",
       " \"(MaxAbsScaler(), FunctionTransformer(func=<ufunc 'log1p'>))\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log transform만 한다.\n",
    "sorted([(logloss, sets) for sets, logloss in set_score.items()])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491f483",
   "metadata": {},
   "source": [
    "- **[Scaling]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260ed221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MaxAbsScaler()\n",
    "# feature_train[num] = scaler.fit_transform(feature_train[num])\n",
    "# feature_test[num] = scaler.transform(feature_test[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f24de8",
   "metadata": {},
   "source": [
    "- **[Transform]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932dc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer =  FunctionTransformer(np.log1p)\n",
    "feature_train[num] = transformer.fit_transform(feature_train[num])\n",
    "feature_test[num] = transformer.transform(feature_test[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfecf7b",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4216d298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_train =  pd.concat([train_ID, feature_train], axis=1)\n",
    "feature_test =  pd.concat([test_ID, feature_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e5d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train.to_csv(path+'/feature_train_transformation.csv', index=False, encoding='cp949')\n",
    "feature_test.to_csv(path+'/feature_test_transformation.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbf369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
